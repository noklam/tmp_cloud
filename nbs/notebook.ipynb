{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "d3b04218-0413-4e6c-8751-5d8a404d73a9",
        "_uuid": "0bca9739b82d5d51e1229243e03ea1b6db35c17e"
      },
      "cell_type": "markdown",
      "source": "## Introduction\n\nThis kernel shows how to use NBSVM (Naive Bayes - Support Vector Machine) to create a strong baseline for the [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge) competition. NBSVM was introduced by Sida Wang and Chris Manning in the paper [Baselines and Bigrams: Simple, Good Sentiment and Topic Classiﬁcation](https://nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf). In this kernel, we use sklearn's logistic regression, rather than SVM, although in practice the two are nearly identical (sklearn uses the liblinear library behind the scenes).\n\nIf you're not familiar with naive bayes and bag of words matrices, I've made a preview available of one of fast.ai's upcoming *Practical Machine Learning* course videos, which introduces this topic. Here is a link to the section of the video which discusses this: [Naive Bayes video](https://youtu.be/37sFIak42Sc?t=3745)."
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "ef06cd19-66b6-46bc-bf45-184e12d3f7d4",
        "_uuid": "cca038ca9424a3f66e10262fc9129de807b5f855",
        "trusted": false
      },
      "cell_type": "code",
      "source": "import pandas as pd, numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "a494f561-0c2f-4a38-8973-6b60c22da357",
        "_uuid": "f70ebe669fcf6b434c595cf6fb7a76120bf7809c",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nsubm = pd.read_csv('../input/sample_submission.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "3996a226-e1ca-4aa8-b39f-6524d4dadb07",
        "_uuid": "2c18461316f17d1d323b1959c8eb4e5448e8a44e"
      },
      "cell_type": "markdown",
      "source": "## Looking at the data\n\nThe training data contains a row per comment, with an id, the text of the comment, and 6 different labels that we'll try to predict."
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "5ddb337b-c9b2-4fec-9652-cb26769dc3c6",
        "scrolled": true,
        "_uuid": "5f5269c56ea6ded273881b0d4dcdb6af83a3e089",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b3b071fb-7a2c-4195-9817-b01983d11c0e",
        "_uuid": "004d2e823056e98afc5adaac433b7afbfe93b82d"
      },
      "cell_type": "markdown",
      "source": "Here's a couple of examples of comments, one toxic, and one with no labels."
    },
    {
      "metadata": {
        "_cell_guid": "2ea37597-02f7-43cf-ad16-a3d50aac1aba",
        "_uuid": "5c4c716de98a4b1c2ecc0e516e67813b4fc1473e"
      },
      "cell_type": "markdown",
      "source": "The length of the comments varies a lot."
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "fd3fe158-4d7f-4b30-ac15-42605240ea4f",
        "_uuid": "9c1a3f81397199fa250a2b642edc7fbc5f9f504e",
        "trusted": false
      },
      "cell_type": "code",
      "source": "lens = train.comment_text.str.len()\nlens.mean(), lens.std(), lens.max()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "d2e55012-4736-425f-84f3-c148ac1f4852",
        "_uuid": "eb68f1c83a5ad11e652ca5f2150993a06d43edb4",
        "trusted": false
      },
      "cell_type": "code",
      "source": "lens.hist();",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b8515824-b2dd-4c95-bbf9-dc74c80355db",
        "_uuid": "0151ab55887071aed82d297acb2c6545ed964c2b"
      },
      "cell_type": "markdown",
      "source": "We'll create a list of all the labels to predict, and we'll also create a 'none' label so we can see how many comments have no labels. We can then summarize the dataset."
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "c3c8fe6b-7e14-45fc-962d-85d9f1cbca9f",
        "_uuid": "25feb9b691dc5628fc33b3c3b0d4c890bfcb415d",
        "trusted": false
      },
      "cell_type": "code",
      "source": "n = len(train)\nseed = 10\nnp.random.seed(seed)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "6ae62334-e1df-4eb0-b457-446d985697a1",
        "_uuid": "3eb139fba211a781b82a162a7b65f433e2f7ee08",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_n = int(n*0.8)\nrandom_idx = np.arange(n)\nrandom_idx = np.random.choice(random_idx,size=n, replace=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "8f4f1125-7d9c-4af7-91a6-3add3a97eead",
        "_uuid": "2b7c4667ee138a767f40bf6a6bea9cce60edf42f",
        "trusted": false
      },
      "cell_type": "code",
      "source": "val = train.iloc[random_idx[train_n:]].copy()\ntrain = train.iloc[random_idx[:train_n]].copy()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "f5cf93b2-048d-472b-8592-36a6ca702bee",
        "_uuid": "05144ad585dd8d0cc88030bf8e29f4bfb5ab0613",
        "trusted": false
      },
      "cell_type": "code",
      "source": "val.shape,train.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "c66f79d1-1d9f-4d94-82c1-8026af198f2a",
        "_uuid": "4ba6ef86c82f073bf411785d971a694348c3efa9",
        "trusted": false
      },
      "cell_type": "code",
      "source": "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\ntrain['none'] = 1-train[label_cols].max(axis=1)\ntrain.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "9f6316e3-7e29-431b-abef-73acf4a08637",
        "_uuid": "b7b0d391248f929a026b16fc38936b7fc0176351",
        "trusted": false
      },
      "cell_type": "code",
      "source": "len(train),len(test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1b221e62-e23f-422a-939d-6747edf2d613",
        "_uuid": "bfdcf59624717b37ca4ffc0c99d2c28a2d419b06"
      },
      "cell_type": "markdown",
      "source": "There are a few empty comments that we need to get rid of, otherwise sklearn will complain."
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "fdba531c-7ef2-4967-88e2-fc2b04f6f2ef",
        "_uuid": "1e1229f403225f1889c7a7b4fc9be90fda818af5",
        "trusted": false
      },
      "cell_type": "code",
      "source": "COMMENT = 'comment_text'\ntrain[COMMENT].fillna(\"unknown\", inplace=True)\nval[COMMENT].fillna(\"unknown\", inplace=True)\ntest[COMMENT].fillna(\"unknown\", inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "480780f1-00c0-4f9a-81e5-fc1932516a80",
        "_uuid": "f2e77e8e6df5e29b620c7a2a0add1438c35af932"
      },
      "cell_type": "markdown",
      "source": "## Building the model\n\nWe'll start by creating a *bag of words* representation, as a *term document matrix*. We'll use ngrams, as suggested in the NBSVM paper."
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "b7f11db7-5c12-4eb8-9f2d-0323d629fed9",
        "_uuid": "b043a3fb66c443fab0129e863c134ec813dadb87",
        "trusted": false
      },
      "cell_type": "code",
      "source": "import re, string\nre_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\ndef tokenize(s): return re_tok.sub(r' \\1 ', s).split()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "bfdebf11-133c-4b12-8664-8bf64757d6cc",
        "_uuid": "941759df15c71d42853515e4d1006f4ab000ce75"
      },
      "cell_type": "markdown",
      "source": "It turns out that using TF-IDF gives even better priors than the binarized features used in the paper. I don't think this has been mentioned in any paper before, but it improves leaderboard score from 0.59 to 0.55."
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "31ad6c98-d054-426c-b3bd-b3b18f52eb6f",
        "_uuid": "75f3f27d56fb2d7d539e65c292d9e77c92ceead3",
        "trusted": false
      },
      "cell_type": "code",
      "source": "n = train.shape[0]\nvec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n               smooth_idf=1, sublinear_tf=1 )\ntrn_term_doc = vec.fit_transform(train[COMMENT])\nval_term_doc = vec.transform(val[COMMENT])\ntest_term_doc = vec.transform(test[COMMENT])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "4cf3ec26-8237-452b-90c9-831cb0297955",
        "_uuid": "6d215bc460e64d88b08f501d5c5a67c290e40635"
      },
      "cell_type": "markdown",
      "source": "This creates a *sparse matrix* with only a small number of non-zero elements (*stored elements* in the representation  below)."
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "4c7bdbcc-4451-4477-944c-772e99bac777",
        "_uuid": "8816cc35f66b9fed9c12978fbdef5bb68fae10f4",
        "trusted": false
      },
      "cell_type": "code",
      "source": "trn_term_doc, test_term_doc, val_term_doc",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "59131479-a861-4f46-add9-b2af09a51976",
        "_uuid": "5fc487461f4c6fdaea25f2cd471fc801856c6689"
      },
      "cell_type": "markdown",
      "source": "Here's the basic naive bayes feature equation:"
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "45fc6070-ba13-455b-9274-5c2611e2809c",
        "_uuid": "8b277f01cecd575ed4fcae2e630c0dd8ce979793",
        "trusted": false
      },
      "cell_type": "code",
      "source": "def pr(y_i, y):\n    p = x[y==y_i].sum(0)\n    return (p+1) / ((y==y_i).sum()+1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "2299d24b-5515-4d37-92d9-e7f6b16a290a",
        "_uuid": "926eaa2e40e588f4ef2b86e0a28f8e575c9ed5f4",
        "trusted": false
      },
      "cell_type": "code",
      "source": "x = trn_term_doc\ntest_x = test_term_doc\nval_x = val_term_doc",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "c0b494ac-0dfc-4faa-a909-0a6d7696d1fc",
        "_uuid": "dc5cafeab86d17ac4f036d58658437636a885a87"
      },
      "cell_type": "markdown",
      "source": "Fit a model for one dependent at a time:"
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "b756c889-a383-4952-9ee9-eca79fd3454f",
        "_uuid": "8652ab2f5f84e77fa395252be9b60be1e44fd583",
        "trusted": false
      },
      "cell_type": "code",
      "source": "def get_mdl(y):\n    y = y.values\n    r = np.log(pr(1,y) / pr(0,y))\n    m = LogisticRegression(C=4, dual=True)\n    x_nb = x.multiply(r)\n    return m.fit(x_nb, y), r",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "33fd5f8c-adfc-45a1-9fde-1769a0993e76",
        "_uuid": "0fa103b5406aabdc36ea9ef21612d343e4982fc4",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# preds = np.zeros((len(test), len(label_cols)))\npreds = np.zeros((len(val), len(label_cols)))\n\nfor i, j in enumerate(label_cols):\n    print('fit', j)\n    m,r = get_mdl(train[j])\n    preds[:,i] = m.predict_proba(val_x.multiply(r))[:,1]\n#   preds[:,i] = m.predict_proba(test_x.multiply(r))[:,1]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "60e587dc-57f1-4380-8746-3d1a2172cd41",
        "_uuid": "74807b7266c56080e2e064abbdd7db69eb0adb67",
        "trusted": false
      },
      "cell_type": "code",
      "source": "m.predict_proba(val_x.multiply(r))[:,1].shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "3c499145-eadf-4cc8-acc0-b51839d99552",
        "_uuid": "cf55ed62144b2894d2f07b8584b0224cb0bd1be4",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train[j].shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "b5155574-823a-4b85-894c-3c7fdeb309be",
        "_uuid": "5dcd9e36621b01fc2403eccb57bb9201c41e76f8",
        "trusted": false
      },
      "cell_type": "code",
      "source": "val_x.shape,x.shape,r.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "d0821d72-94c3-455d-81f7-a46379cd09cf",
        "_uuid": "179c4a9b205382c502941cc7559fea701f567091",
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import *",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "276d6331-4fee-4042-848d-e330048cd01b",
        "_uuid": "6e1bc9b8bd76993e8de5a187682e41006fdee57c",
        "trusted": false
      },
      "cell_type": "code",
      "source": "def score(preds_prob, df, cols):\n    auc_list =[]\n    for i,col in enumerate(cols):\n        frp,trp,thres = roc_curve(df[col],preds_prob[:,i])\n        auc_val =auc(frp,trp)\n        auc_list.append(auc_val)\n    print(auc_list)\n    print('Average AUC',np.mean(auc_list))\n    return auc_list\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "fe50b5cf-efa3-4ae3-8cb2-124225732a03",
        "_uuid": "f62ddb54bfa7ac7100b0a858de2fe5de96e45047",
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "b9223361-3f89-4fcf-979a-70611f92e602",
        "_uuid": "26052c1ddf0874e99bb21652b2118ba7971b3d50",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Here is how we get a model from a bag of words\nsl = 2000\nmd = TextClassifierData.from_bow(trn_term_doc, trn_y, val_term_doc, val_y, sl)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "3727676b-64a9-4512-a3db-044348b4f55a",
        "_uuid": "9b0c7dab1e508f452c4386bd0db020cbe03206be",
        "trusted": false
      },
      "cell_type": "code",
      "source": "cols = ['toxic', 'severe_toxic','obscene','threat','insult','identity_hate']\n\nscore(preds, val, cols)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1a99c4d9-916f-4189-9a25-fedcb7700336",
        "_uuid": "5525045116474e6d12b6edc890250d30c0790f06"
      },
      "cell_type": "markdown",
      "source": "And finally, create the submission file."
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "4fd47f06-d0c4-4cdb-ac82-0082f545d88e",
        "_uuid": "7c4013b1bff9d6ad6e095b2268f52fef3be12056",
        "trusted": false
      },
      "cell_type": "code",
      "source": "preds = np.zeros((len(test), len(label_cols)))\n\nfor i, j in enumerate(label_cols):\n    print('fit', j)\n    m,r = get_mdl(train[j])\n    preds[:,i] = m.predict_proba(test_x.multiply(r))[:,1]\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "be48e359-7fbf-4674-a025-23a4d3c69b81",
        "_uuid": "7335208f767061bc73bd97e7030b901caa8302c1",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "4596ae08-df4a-4ed4-a237-7bda295b549a",
        "_uuid": "d5d14c9d77903902d82392f1865669419e76a514",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train.to_csv('train.csv', index=False)\nval.to_csv('valid.csv', index=False)\ntest.to_csv('test.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "bc6a4575-fbbb-47ea-81ac-91fa702dc194",
        "_uuid": "5dd033a93e6cf32cdbdaa0a8b05cd8d27de2b21d",
        "trusted": false
      },
      "cell_type": "code",
      "source": "submid = pd.DataFrame({'id': subm[\"id\"]})\nsubmission = pd.concat([submid, pd.DataFrame(preds, columns = label_cols)], axis=1)\nsubmission.to_csv('submission_NBSVM.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "aebb90a6-fd14-4bc0-8304-0e679f734e11",
        "_uuid": "727b42daae4f55b343a8a2dd9df4657160159bc8",
        "trusted": false
      },
      "cell_type": "code",
      "source": "submission.tail()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "1c345d02-b768-491c-8c03-8c3459a552a8",
        "_uuid": "adbbfb0156952a6a43833e337b8a418ccac257aa",
        "trusted": false
      },
      "cell_type": "code",
      "source": "##  Average AUC Val_score 0.981634067806 ,LB 0.9768  --NBSVM [0.98144098423683201, 0.98476840219423045, 0.9868337419349632, 0.98839661171873294, 0.98080315759448733, 0.96756150915437933]\n## [0.97853728593930467, 0.98644023203740394, 0.98782481698417657, 0.99269738101154825, 0.97976522049219994, 0.97140618781604837]\n#Average AUC 0.982778520713",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "716c3876-ce78-46fe-b4f1-46f0c58ed2f7",
        "_uuid": "9748e60600123457c0058bfb4b80d81a597ddacc",
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "b9758397-52bb-4de9-bb2b-b36bb5a16c88",
        "_uuid": "9751d784d0662a3d410d403fd18cd176744379bd",
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "2a2d4c31-ae78-4e96-81f9-b9d6e336d652",
        "_uuid": "82d39208af73edd7e90356d5083452d80c372675",
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "nbconvert_exporter": "python",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "pygments_lexer": "ipython3",
      "name": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}